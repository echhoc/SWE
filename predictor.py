import streamlit as st
import pandas as pd
import numpy as np
import joblib
import shap
import matplotlib.pyplot as plt
from pathlib import Path

# =========================
# é¡µé¢æ ‡é¢˜
# =========================
st.title("DPN vs Normal Prediction (SWE + Radiomics)")
st.caption("Based on duration, CSA, PCA features and radiomics features")

# =========================
# âœ… å…³é”®ï¼šç”¨è„šæœ¬ç›®å½•å®šä½æ–‡ä»¶ï¼ˆå…¼å®¹ Streamlit Cloud/Linuxï¼‰
# =========================
BASE_DIR = Path(__file__).resolve().parent
MODEL_PATH = BASE_DIR / "LGB.pkl"
DEFAULT_DATA_PATH = BASE_DIR / "å‰ªåˆ‡æ³¢æ•°æ®_ç»“åˆ_val_select.xlsx"  # ä½ ä»“åº“é‡Œçš„æ–‡ä»¶å

# ï¼ˆå¯é€‰ï¼‰è°ƒè¯•ï¼šçœ‹çœ‹äº‘ç«¯æ˜¯å¦è¯†åˆ«åˆ°äº†æ–‡ä»¶
# st.write("BASE_DIR:", str(BASE_DIR))
# st.write("Files:", [p.name for p in BASE_DIR.iterdir()])
# st.write("MODEL_PATH exists:", MODEL_PATH.exists())
# st.write("DATA_PATH exists:", DEFAULT_DATA_PATH.exists())

if not MODEL_PATH.exists():
    st.error(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ï¼š{MODEL_PATH.name}ï¼ˆè¯·ç¡®è®¤å®ƒå’Œ predictor.py åœ¨åŒä¸€ç›®å½•ï¼‰")
    st.stop()

if not DEFAULT_DATA_PATH.exists():
    st.error(f"âŒ æ‰¾ä¸åˆ°é»˜è®¤æ•°æ®æ–‡ä»¶ï¼š{DEFAULT_DATA_PATH.name}ï¼ˆè¯·ç¡®è®¤å®ƒå’Œ predictor.py åœ¨åŒä¸€ç›®å½•ï¼‰")
    st.stop()

# =========================
# è½½å…¥æ¨¡å‹ & é»˜è®¤æ•°æ®
# =========================
model = joblib.load(MODEL_PATH)
df_default = pd.read_excel(DEFAULT_DATA_PATH)

# æ ‡ç­¾åˆ—åï¼šå¦‚æœæ˜¯ target/label äºŒé€‰ä¸€
label_col = None
for c in ["target", "label"]:
    if c in df_default.columns:
        label_col = c
        break

X_default = df_default.drop(columns=[label_col]) if label_col else df_default.copy()

# =========================
# ä½ çš„ 22 ä¸ªç‰¹å¾ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
# =========================
feature_names = [
    "duration",
    "CSA",
    "PCA_6",
    "PCA_61",
    "PCA_59",
    "PCA_27",
    "PCA_7",
    "PCA_12",
    "PCA_11",
    "PCA_14",
    "PCA_38",
    "PCA_2",
    "lbp-2D_firstorder_10Percentile",
    "original_firstorder_RootMeanSquared",
    "wavelet-LLH_firstorder_Variance",
    "original_glrlm_GrayLevelNonUniformity",
    "exponential_glrlm_RunEntropy",
    "original_gldm_LargeDependenceLowGrayLevelEmphasis",
    "wavelet-LLH_glrlm_ShortRunEmphasis",
    "exponential_glrlm_GrayLevelNonUniformity",
    "wavelet-LHL_glszm_SmallAreaHighGrayLevelEmphasis",
    "wavelet-HHL_glszm_LargeAreaEmphasis",
]

# âœ… å¦‚æœé»˜è®¤æ•°æ®é‡Œåˆ—ä¸å…¨ï¼Œç›´æ¥æç¤ºï¼ˆé¿å…åé¢ç¥ç§˜æŠ¥é”™ï¼‰
missing = [c for c in feature_names if c not in X_default.columns]
if missing:
    st.error(f"é»˜è®¤æ•°æ®ç¼ºå°‘è¿™äº›ç‰¹å¾åˆ—ï¼š{missing}\nè¯·ç¡®è®¤ Excel è¡¨å¤´ä¸æ¨¡å‹è®­ç»ƒä¸€è‡´ã€‚")
    st.stop()

# åªå–è¿™äº›åˆ—ï¼Œå¹¶æŒ‰ feature_names æ’åºï¼ˆå¼ºåˆ¶å¯¹é½åˆ—é¡ºåºï¼‰
X_default = X_default[feature_names]

# =========================
# è¾“å…¥è¡¨å•
# =========================
with st.form("input_form"):
    st.subheader("è¯·è¾“å…¥ä»¥ä¸‹ç‰¹å¾ï¼ˆå¯ç”¨é»˜è®¤ä¸­ä½æ•°ï¼‰")

    inputs = {}
    for col in feature_names:
        default_val = float(X_default[col].median())

        if col == "duration":
            inputs[col] = st.number_input(col, value=float(default_val), min_value=0.0, max_value=1000.0, step=1.0)
        elif col == "CSA":
            inputs[col] = st.number_input(col, value=float(default_val), min_value=0.0, max_value=10.0,
                                          step=0.01, format="%.4f")
        else:
            inputs[col] = st.number_input(col, value=float(default_val), step=0.01, format="%.6f")

    submitted = st.form_submit_button("Submit Prediction")

# =========================
# é¢„æµ‹ & è§£é‡Š
# =========================
if submitted:
    model_input = pd.DataFrame([inputs], columns=feature_names)

    st.subheader("Model Input Features")
    st.dataframe(model_input)

    # é¢„æµ‹æ¦‚ç‡ï¼ˆclass=1ï¼‰
    predicted_proba = model.predict_proba(model_input)[0]
    probability = predicted_proba[1] * 100
    st.subheader("Prediction Result")
    st.markdown(f"**Estimated probability (class=1):** {probability:.1f}%")

    # ===== åˆ†å±‚é˜ˆå€¼ï¼šç”¨é»˜è®¤æ•°æ®åˆ†ä½æ•° =====
    y_probs = model.predict_proba(X_default)[:, 1]
    low_th = np.percentile(y_probs, 50)
    mid_th = np.percentile(y_probs, 88.07)

    if predicted_proba[1] <= low_th:
        st.success("ğŸŸ¢ Low risk / predicted as Normal tendency")
    elif predicted_proba[1] <= mid_th:
        st.warning("ğŸŸ¡ Moderate risk")
    else:
        st.error("ğŸ”´ High risk / predicted as DPN tendency")

    # ===== SHAP Force Plotï¼ˆé™æ€å›¾ï¼‰=====
    st.subheader("SHAP Force Plot (Local Explanation)")

    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(model_input)

    # äºŒåˆ†ç±»å…¼å®¹
    if isinstance(shap_values, list):
        shap_value_sample = shap_values[1][0]      # (n_features,)
        expected_value = explainer.expected_value[1]
    else:
        shap_value_sample = shap_values[0]
        expected_value = explainer.expected_value

    plt.figure()
    shap.force_plot(
        base_value=expected_value,
        shap_values=shap_value_sample,
        features=model_input.iloc[0],
        matplotlib=True,
        show=False
    )

    out_png = str(BASE_DIR / "shap_force_plot.png")  # âœ… ä¿å­˜åˆ°è„šæœ¬ç›®å½•æ›´ç¨³
    plt.savefig(out_png, bbox_inches="tight", dpi=300)
    plt.close()

    st.image(out_png)


